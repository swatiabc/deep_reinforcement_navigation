{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_size:  4\n",
      "action:  1 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  0.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  1.0 Reward:  1.0 done:  False\n",
      "action:  0 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  1.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  2.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  1.0 Reward:  -1.0 done:  False\n",
      "action:  1 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  1 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  0 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  2 score:  1.0 Reward:  0.0 done:  False\n",
      "action:  3 score:  1.0 Reward:  0.0 done:  True\n",
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "print(\"action_size: \",action_size)\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state   \n",
    "    print(\"action: \",action, \"score: \",score, \"Reward: \",reward, \"done: \",done)      # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: box2d in /usr/local/anaconda3/envs/drlnd/lib/python3.6/site-packages (2.3.10)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "!pip3 install box2d\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "    \n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from dq_agent import Agent\n",
    "agent = Agent(state_size=37, action_size=4, seed=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 1.10\n",
      "Episode 200\tAverage Score: 4.51\n",
      "Episode 300\tAverage Score: 7.45\n",
      "Episode 400\tAverage Score: 10.57\n",
      "Episode 500\tAverage Score: 13.06\n",
      "Episode 600\tAverage Score: 14.38\n",
      "Episode 700\tAverage Score: 15.32\n",
      "Episode 800\tAverage Score: 16.36\n",
      "Episode 900\tAverage Score: 16.23\n",
      "Episode 907\tAverage Score: 16.50\n",
      "Environment solved in 807 episodes!\tAverage Score: 16.50\n"
     ]
    }
   ],
   "source": [
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    eps = eps_start\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "        state = env_info.vector_observations[0]            # get the current state\n",
    "        score = 0                                          # initialize the score\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)                 # select an action\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            score += reward                                # update the score\n",
    "            state = next_state\n",
    "            # print(\"i_episode: \",i_episode, \"t: \",t, \"score: \",score, \"reward: \",reward)\n",
    "            if done:\n",
    "                break\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=16.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[-5.2084e-02, -3.4161e-02, -5.0875e-02,  ..., -2.1501e+00,\n",
      "         -1.9058e-03, -1.5683e-03],\n",
      "        [-4.4056e-02,  1.8648e-01,  1.4121e-01,  ..., -2.4639e-01,\n",
      "          7.6475e-02, -1.3798e-02],\n",
      "        [-6.9279e-02,  3.9490e-02,  1.5006e-01,  ...,  1.5252e-01,\n",
      "         -1.1908e-03,  1.9599e-02],\n",
      "        ...,\n",
      "        [ 3.0416e-01, -2.7702e-01, -3.2794e-01,  ...,  2.3368e-01,\n",
      "          3.0488e-02, -1.9350e-02],\n",
      "        [-2.6700e-01,  5.9221e-02, -1.0069e-01,  ..., -2.4214e-01,\n",
      "         -4.3376e-02, -1.4783e-02],\n",
      "        [ 2.7336e-01, -1.3823e-01, -5.0527e-01,  ..., -3.7620e-02,\n",
      "         -4.1441e-02, -2.2646e-02]])), ('fc1.bias', tensor([ 0.2024, -0.0821, -0.0846, -0.0599, -0.0870, -0.1529, -0.0662,\n",
      "        -0.0450, -0.1505,  0.0393, -0.0522, -0.1312, -0.0217, -0.1350,\n",
      "         0.0845, -0.0527, -0.1388, -0.0213, -0.0066, -0.1122,  0.0449,\n",
      "         0.0071,  0.0574,  0.1662, -0.0840,  0.0251, -0.1549,  0.1311,\n",
      "         0.1335, -0.1588,  0.0747,  0.1214,  0.1791,  0.0105,  0.0466,\n",
      "        -0.0451,  0.0120, -0.1627,  0.0129, -0.0662,  0.0639,  0.2001,\n",
      "        -0.1080,  0.1244,  0.0092,  0.0422,  0.2298, -0.0096,  0.0634,\n",
      "         0.0093,  0.1436, -0.2953,  0.1561, -0.0322,  0.0616, -0.0463,\n",
      "         0.0832,  0.0162, -0.0837,  0.1159,  0.0253, -0.0958, -0.1487,\n",
      "         0.0253])), ('fc2.weight', tensor([[ 0.4891, -0.2129, -0.2113,  ..., -0.0424, -0.0417,  0.0995],\n",
      "        [ 0.2193,  0.2253, -0.4438,  ..., -0.3425,  0.0541, -0.2146],\n",
      "        [-0.0713, -0.2694, -0.0795,  ...,  0.0367,  0.2722,  0.2446],\n",
      "        ...,\n",
      "        [ 0.1499, -0.0397, -0.1021,  ...,  0.3433,  0.0491,  0.4442],\n",
      "        [-0.0984,  0.3904, -0.3263,  ...,  0.0583, -0.1729,  0.1731],\n",
      "        [-0.0169,  0.0322,  0.0151,  ...,  0.0939, -0.0133, -0.1053]])), ('fc2.bias', tensor([ 0.0742,  0.0340, -0.0685, -0.1656,  0.4152,  0.2201, -0.1082,\n",
      "        -0.0642,  0.0539,  0.0604,  0.0238, -0.2713,  0.0909,  0.1432,\n",
      "         0.2393,  0.1056, -0.2332,  0.1825, -0.2591,  0.2057,  0.0316,\n",
      "         0.1647,  0.2749, -0.0104,  0.2111,  0.3786, -0.2443, -0.0638,\n",
      "         0.6477,  0.1453, -0.0326,  0.6508,  0.4207, -0.0978,  0.1244,\n",
      "         0.0127, -0.0549, -0.0910,  0.5305,  0.3917, -0.1759, -0.0248,\n",
      "         0.6747, -0.2943,  0.1516, -0.0310,  0.1543,  0.0443, -0.2557,\n",
      "         0.1123, -0.0561,  0.2029, -0.1053,  0.0841,  0.2418, -0.1377,\n",
      "         0.3092, -0.0827, -0.0700,  0.1979, -0.0434,  0.0540, -0.1483,\n",
      "         0.1674])), ('fc3.weight', tensor([[ 0.3140, -0.4438, -0.2333, -0.3142,  0.2360,  0.2134, -0.0660,\n",
      "         -0.1159, -0.0750,  0.0530,  0.2111, -0.2224,  0.1327,  0.3174,\n",
      "          0.2050,  0.1129, -0.1509,  0.0721, -0.1342,  0.2284, -0.0033,\n",
      "          0.1246,  0.0028,  0.1990,  0.2086,  0.1018, -0.2429, -0.0421,\n",
      "          0.2747,  0.1552,  0.2834,  0.1948,  0.1514,  0.1491,  0.1735,\n",
      "          0.3182, -0.0919, -0.1963,  0.2348,  0.1764, -0.0674, -0.0141,\n",
      "          0.2393, -0.2412,  0.0543, -0.1699,  0.1011,  0.1126, -0.2002,\n",
      "          0.1079, -0.4528,  0.4037,  0.0272,  0.1192,  0.3873,  0.0537,\n",
      "          0.1918,  0.0096, -0.1898,  0.4708,  0.2818,  0.1611, -0.3828,\n",
      "          0.1618],\n",
      "        [ 0.3359, -0.1040,  0.4525, -0.1039,  0.2965,  0.2471,  0.2804,\n",
      "         -0.0634, -0.3684,  0.1291,  0.0902, -0.1277,  0.1751,  0.2705,\n",
      "          0.3203,  0.2180, -0.1237,  0.0655, -0.1515,  0.1117, -0.0277,\n",
      "          0.1262,  0.1241,  0.2877,  0.1290,  0.1383,  0.0014, -0.0955,\n",
      "          0.2083,  0.1387,  0.4901,  0.2261,  0.1562,  0.2950,  0.1887,\n",
      "          0.3945, -0.2928, -0.2684,  0.1929,  0.1392,  0.1306, -0.1097,\n",
      "          0.2213, -0.2476,  0.2849, -0.2155,  0.1245,  0.2268, -0.0965,\n",
      "          0.2561, -0.1658,  0.4036, -0.1622,  0.1981,  0.3153, -0.0235,\n",
      "          0.2456, -0.1051, -0.0194,  0.3956,  0.2320,  0.3403,  0.0286,\n",
      "          0.2029],\n",
      "        [ 0.1739, -0.0310, -0.2607, -0.2776,  0.2446,  0.2342,  0.0102,\n",
      "          0.0837, -0.1921,  0.3063,  0.1040, -0.1193,  0.1752,  0.0017,\n",
      "          0.0334,  0.3988, -0.1356, -0.2423,  0.1665,  0.1363, -0.0090,\n",
      "          0.0777,  0.2094,  0.3938,  0.0576,  0.2165, -0.1724, -0.0478,\n",
      "          0.1586,  0.4709,  0.5952,  0.2201,  0.2327, -0.0704,  0.1612,\n",
      "          0.4111, -0.1023,  0.0282,  0.1690,  0.2041,  0.1374,  0.2643,\n",
      "          0.2587, -0.4066,  0.2325, -0.0515,  0.0196,  0.3333, -0.0591,\n",
      "          0.6777, -0.4143,  0.0840, -0.5369, -0.0683,  0.1863, -0.0905,\n",
      "          0.0281,  0.2658,  0.0025,  0.3752,  0.4735,  0.3641, -0.4337,\n",
      "          0.2525],\n",
      "        [ 0.3139, -0.3555,  0.0687, -0.2210,  0.3338,  0.2065,  0.4841,\n",
      "         -0.1611, -0.5132,  0.2939, -0.3722, -0.0771,  0.4069,  0.0401,\n",
      "          0.1820,  0.1966, -0.3540, -0.2172,  0.0878, -0.0220,  0.4050,\n",
      "          0.2412,  0.1280,  0.0677,  0.0013,  0.2121, -0.1834,  0.1637,\n",
      "          0.2640,  0.1507, -0.2588,  0.2033,  0.1001,  0.2898,  0.3911,\n",
      "          0.1401, -0.1752, -0.4227,  0.2124,  0.1984,  0.1697,  0.0906,\n",
      "          0.2817, -0.0794,  0.1497, -0.3067, -0.0697, -0.1417, -0.2474,\n",
      "          0.2708, -0.1494,  0.3916, -0.2720, -0.0131,  0.2231, -0.0140,\n",
      "          0.1115, -0.4807,  0.0460,  0.4474,  0.2513,  0.4716, -0.3920,\n",
      "          0.5288]])), ('fc3.bias', tensor([ 0.4648,  0.3508,  0.4222,  0.3410]))])\n"
     ]
    }
   ],
   "source": [
    "print(agent.qnetwork_local.state_dict())\n",
    "torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 21.0\n"
     ]
    }
   ],
   "source": [
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:      \n",
    "    action = agent.act(state)                      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
